{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating model inference and scaling to unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDos:\n",
    "\n",
    "# 1. Implement model inference based on finetuned transformer (on cloud) [DONE]\n",
    "# 2. Aggregate inference of entities in one sentence into aggregated certainty score (ACS) [DONE]\n",
    "# 3. Detokenize dataset from word tokens into sentence to be labeled (will this worsen results?) [DONE]\n",
    "# 4. Scale ACS inference to hf dataset and rank by ACS score [DONE]\n",
    "# 5. Scale to selected dataset slices and return as new input dataset [DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration dxiao--requirements-ner-a9d27206730c3bd0\n",
      "Found cached dataset json (C:/Users/dekai/.cache/huggingface/datasets/dxiao___json/dxiao--requirements-ner-a9d27206730c3bd0/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d69b3f9aaf944eaade2dfdf15f55b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model config\n",
    "\n",
    "input_model = \"dxiao/bert-finetuned-ner-10percent\"\n",
    "input_dataset = 'dxiao/requirements-ner-id'\n",
    "step_size = 60\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(input_model)\n",
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "xiao_data = load_dataset(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detokenize dataset\n",
    "import re\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok\n",
    "\n",
    "def detokenize(token_list):\n",
    "    detokenizer = Detok()\n",
    "    text = detokenizer.detokenize(token_list)\n",
    "    text = re.sub('\\s*,\\s*', ', ', text)\n",
    "    text = re.sub('\\s*\\.\\s*', '.', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average of all certainty scores in ner_results\n",
    "# might be calculated faster -> Vectorize with np\n",
    "def calculate_ACS(text):\n",
    "    ner_results = pipe(text)\n",
    "    certainty_score_list = []\n",
    "    for i in ner_results:\n",
    "        certainty_score_list.append(i['score'])\n",
    "    if not certainty_score_list: # if list is empty\n",
    "        aggregated_certainty_score = 0\n",
    "    else:\n",
    "        aggregated_certainty_score = sum(certainty_score_list)/len(certainty_score_list)\n",
    "    return aggregated_certainty_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset input has to be 'train' set\n",
    "\n",
    "def top_candidates(dataset, step_size):\n",
    "    candidate_list = []\n",
    "    df = dataset.to_pandas()\n",
    "    # detokenize tokens into new text column\n",
    "    df['text'] = df['tokens'].apply(lambda x: detokenize(x))\n",
    "    # inference calculation of ACS and new ACS columns\n",
    "    df['ACS'] = df['text'].apply(lambda x: calculate_ACS(x)) # takes ~30s for 600 rows\n",
    "    # rank from lowest ACS to highest\n",
    "    df = df.sort_values(by='ACS')\n",
    "    candidate_list = list(df.index[:step_size])\n",
    "    non_candidate_list = list(df.index[step_size+1:])\n",
    "    return candidate_list, non_candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform inference_aggregation and batched mapping\n",
    "# input dataset has to be input_dataset['train']\n",
    "# i.e.: input_train_dataset = seed dataset (60 sentences)\n",
    "# i.e.: input_inference_dataset = remaining dataset (540 sentences)\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "def inference_aggregation(input_train_dataset, input_inference_dataset, step_size):\n",
    "    candidate_list, non_candidate_list = top_candidates(input_inference_dataset, step_size)\n",
    "    added_inference_dataset = input_inference_dataset.select(candidate_list) # select candidates\n",
    "    \n",
    "    output_train_dataset = concatenate_datasets([input_train_dataset, added_inference_dataset]) # add candidates to train_dataset\n",
    "    output_inference_dataset = input_inference_dataset.select(non_candidate_list) # remaining rows become new inference_dataset \n",
    "\n",
    "    return output_train_dataset, output_inference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = inference_aggregation(\n",
    "    xiao_data['train'].select(range(60)), xiao_data['train'].select(range(61,xiao_data['train'].num_rows)), step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return id of top 60 (variable) lowest ACS scores is list\n",
    "lowest_ACS = list(df_xiao_train['id'][:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE IN EXAMPLE HERE\n",
    "example = \"The Payload shall resist an acceleration of at least 60Gs of shocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# displays inference for one sentence\n",
    "def display_inference(text):\n",
    "    ner_results = pipe(text)\n",
    "    spacy_pipe = spacy.blank(\"en\")\n",
    "    doc = spacy_pipe(text)\n",
    "\n",
    "    ents = []\n",
    "    for i in ner_results:\n",
    "        span = doc.char_span(i['start'], i['end'], label=i['entity_group']) #None if mapping issue\n",
    "        ents.append(span)\n",
    "    doc.ents = ents \n",
    "\n",
    "    colors = {\"ENT\": \"#C5BDF4\", \"ACT\": \"#FFD882\", \"ATTR\": \"#D9FBAD\", \"RELOP\": \"#FFDAF9\", \"QUANT\": \"#C2F2F6\"}\n",
    "    options = {\"ents\": ['ENT', 'ACT', 'ATTR', 'RELOP', 'QUANT'], \"colors\": colors}\n",
    "\n",
    "    displacy.render(doc, style = 'ent', options = options)\n",
    "\n",
    "    for i in ner_results:\n",
    "        print(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0069e35276b4b16933fc948b1a9f9ae6be664e95860c7c07ee003b238b1460ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
